{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f162208e-d4b0-424a-b30f-5ce2a239c506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\avina\\anaconda3\\envs\\nlp\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\avina\\anaconda3\\envs\\nlp\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\avina\\anaconda3\\envs\\nlp\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\avina\\anaconda3\\envs\\nlp\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\avina\\anaconda3\\envs\\nlp\\lib\\site-packages (from nltk) (4.67.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\avina\\anaconda3\\envs\\nlp\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97204b50-8fbf-4739-9658-9c20427a4514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\avina\\anaconda3\\envs\\nlp\\lib\\site-packages (from seaborn) (2.1.3)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\avina\\anaconda3\\envs\\nlp\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\avina\\anaconda3\\envs\\nlp\\lib\\site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\avina\\anaconda3\\envs\\nlp\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\avina\\anaconda3\\envs\\nlp\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\avina\\anaconda3\\envs\\nlp\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\avina\\anaconda3\\envs\\nlp\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\avina\\anaconda3\\envs\\nlp\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\avina\\anaconda3\\envs\\nlp\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\avina\\anaconda3\\envs\\nlp\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\avina\\anaconda3\\envs\\nlp\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\avina\\anaconda3\\envs\\nlp\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\avina\\anaconda3\\envs\\nlp\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\avina\\anaconda3\\envs\\nlp\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2081b878-3dce-47e9-bafd-210b7374a667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\avina\\anaconda3\\envs\\nlp\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\avina\\anaconda3\\envs\\nlp\\lib\\site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\avina\\anaconda3\\envs\\nlp\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\avina\\anaconda3\\envs\\nlp\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\avina\\anaconda3\\envs\\nlp\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a2b6ae5-9a9c-4a7a-a90c-be60a23cdd0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 label                                               text  \\\n",
       "0         605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1        2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2        3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4        2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "   label_num  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_find = pd.read_csv(r\"C:\\Users\\avina\\Downloads\\spam_ham_dataset.csv\")\n",
    "\n",
    "df_find.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1088a56f-bf64-411a-ad23-90e2dc80eec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label           object\n",
      "text            object\n",
      "label_num        int64\n",
      "text_cleaned    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_find.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91d9102e-e41f-441e-ab76-91feabcf171f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reg</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    reg label                                               text  label_num\n",
       "0   605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...          0\n",
       "1  2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...          0\n",
       "2  3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...          0\n",
       "3  4685  spam  Subject: photoshop , windows , office . cheap ...          1\n",
       "4  2030   ham  Subject: re : indian springs\\r\\nthis deal is t...          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_find.rename(columns={'Unnamed: 0':'reg'},inplace=True)\n",
    "df_find.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4943753e-8149-40e8-a317-c371ed33ba51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5171 entries, 0 to 5170\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   reg        5171 non-null   int64 \n",
      " 1   label      5171 non-null   object\n",
      " 2   text       5171 non-null   object\n",
      " 3   label_num  5171 non-null   int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 161.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_find.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cd1e7b1-8545-4454-9d10-a7260e69df03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  label_num\n",
       "0   ham  Subject: enron methanol ; meter # : 988291\\r\\n...          0\n",
       "1   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...          0\n",
       "2   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...          0\n",
       "3  spam  Subject: photoshop , windows , office . cheap ...          1\n",
       "4   ham  Subject: re : indian springs\\r\\nthis deal is t...          0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_find.drop(columns=['reg'],inplace=True)\n",
    "\n",
    "df_find.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "037395a9-557e-4ef4-9e25-940717f52a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  label_num\n",
       "0   ham  Subject: enron methanol ; meter # : 988291\\r\\n...          0\n",
       "1   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...          0\n",
       "2   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...          0\n",
       "3  spam  Subject: photoshop , windows , office . cheap ...          1\n",
       "4   ham  Subject: re : indian springs\\r\\nthis deal is t...          0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_find['label_num'] = df_find['label'].map({'ham' : 0,'spam' : 1})\n",
    "df_find.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b1bde08-b4d4-4bf0-b233-00223ffcf903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\avina\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\avina\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23aabf6f-4b69-478b-b76b-46f9bad12040",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\avina\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')  # Ensure wordnet is downloaded for lemmatization\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "stop_words =  set(stopwords.words('english'))\n",
    "\n",
    "def text_cleaner(text):\n",
    "    text = re.sub(r'[^0-9a-zA-Z\\s]', '', text)  # Remove punctuation\n",
    "    words = word_tokenize(text.lower())  # Tokenization and lowercase\n",
    "    words = [lemmatizer.lemmatize(w) for w in words if w not in stop_words]  # Lemmatization\n",
    "    return ' '.join(words)\n",
    "\n",
    "df_find['text_cleaned'] = df_find['text'].apply(text_cleaner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "997527c4-0c40-4b86-a786-f908977b3d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_find['text_cleaned'] = df_find['text'].apply(text_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08eb0972-33b4-47f5-a7ac-0f2ab069ce20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       subject enron methanol meter 988291 follow not...\n",
      "1       subject hpl nom january 9 2001 see attached fi...\n",
      "2       subject neon retreat ho ho ho around wonderful...\n",
      "3       subject photoshop window office cheap main tre...\n",
      "4       subject indian spring deal book teco pvr reven...\n",
      "                              ...                        \n",
      "5166    subject put 10 ft transport volume decreased 2...\n",
      "5167    subject 3 4 2000 following noms hpl take extra...\n",
      "5168    subject calpine daily gas nomination julie men...\n",
      "5169    subject industrial worksheet august 2000 activ...\n",
      "5170    subject important online banking alert dear va...\n",
      "Name: text_cleaned, Length: 5171, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_find['text_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b896012-0510-4360-ac41-6930e36adb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features =5000)\n",
    "X = tfidf.fit_transform(df_find['text_cleaned']).toarray()\n",
    "Y = df_find['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77f0547c-3411-4d1f-ba31-a57725a965b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9845410628019323"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "LG = LogisticRegression()\n",
    "LG.fit(X_train,Y_train)\n",
    "predict_LG = LG.predict(X_test)\n",
    "\n",
    "LG.score(X_test,Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb8e3653-fe93-462f-a561-111a188baad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       742\n",
      "        spam       0.97      0.98      0.97       293\n",
      "\n",
      "    accuracy                           0.98      1035\n",
      "   macro avg       0.98      0.98      0.98      1035\n",
      "weighted avg       0.98      0.98      0.98      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,predict_LG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13561e67-1e38-4691-a314-af4cb6274c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9130434782608695"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DT = DecisionTreeClassifier(max_depth=10,min_samples_split=5)\n",
    "DT.fit(X_train,Y_train)\n",
    "predict_DT = DT.predict(X_test)\n",
    "\n",
    "DT.score(X_test,Y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c74d68c-a575-4dd2-995b-b3d62e342203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.89      0.99      0.94       672\n",
      "        spam       0.97      0.78      0.86       363\n",
      "\n",
      "    accuracy                           0.91      1035\n",
      "   macro avg       0.93      0.88      0.90      1035\n",
      "weighted avg       0.92      0.91      0.91      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predict_DT,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "864b00c9-b276-4d99-a711-124bab3794c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# GB = GradientBoostingClassifier()\n",
    "# GB.fit(X_train,Y_train)\n",
    "# predict_GB = GB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "762aa31f-82e5-4c20-9884-40cd7d42ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GB.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cad70b2-a560-407d-8881-aadd4eb37c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(predict_GB,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f37a696-491f-417d-b77c-218953f61f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def output(n):\n",
    "    if n == 1:\n",
    "        return 'spam'\n",
    "    elif n == 0:\n",
    "        return 'not spam'\n",
    "    else:\n",
    "        return 'not a spam and nor ham'\n",
    "\n",
    "\n",
    "\n",
    "def testing(email):\n",
    "    texting = {'text':[email]}\n",
    "    new_dataFrame = pd.DataFrame(texting)\n",
    "    new_dataFrame['text'] = new_dataFrame['text'].apply(text_cleaner)\n",
    "    new_x = new_dataFrame['text']\n",
    "    new_xv = tfidf.transform(new_x)\n",
    "    LG_predict = LG.predict(new_xv)\n",
    "    DT_predict = DT.predict(new_xv)\n",
    "\n",
    "    return f\"LG_prediction {LG_predict[0]}, DT_prediction {DT_predict[0]}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "842882b4-8cc8-4fbd-b460-8b8119803a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Subject: Meeting Reminder: Project Update Body:  Hi [Recipient's Name],  Just a quick reminder about our project update meeting tomorrow at 10:00 AM in the conference room. We will discuss the following topics:  Current progress on the ongoing tasks Upcoming deadlines and responsibilities Addressing any blockers or challenges Please be prepared to give a brief update on your assigned tasks. If you have any additional items you'd like to add to the agenda, feel free to let me know.  Looking forward to catching up tomorrow.  Best regards, [Your Name] [Your Position] [Your Company Name]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LG_prediction ham, DT_prediction spam'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email = str(input())\n",
    "testing(email)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
